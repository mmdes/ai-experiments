{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification \n",
    "\n",
    "Database: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>205.00000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>144.00000</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>159.0000</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>277.00000</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.74</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>124.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9456.00</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius_mean   texture_mean   perimeter_mean   area_mean  \\\n",
       "0           17.99          10.38           122.80      1001.0   \n",
       "1           20.57          17.77           132.90      1326.0   \n",
       "2           19.69          21.25           130.00      1203.0   \n",
       "3           11.42          20.38            77.58       386.1   \n",
       "4           20.29          14.34           135.10      1297.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564         21.56          22.39           142.00      1479.0   \n",
       "565         20.13          28.25           131.20      1261.0   \n",
       "566         16.60          28.08           108.30       858.1   \n",
       "567         20.60          29.33           140.10      1265.0   \n",
       "568          7.76          24.54            47.92       181.0   \n",
       "\n",
       "      smoothness_mean   compactness_mean   concavity_mean  \\\n",
       "0             0.11840            0.27760          0.30010   \n",
       "1             0.08474            0.07864          0.08690   \n",
       "2             0.10960            0.15990          0.19740   \n",
       "3             0.14250            0.28390          0.24140   \n",
       "4             0.10030            0.13280        198.00000   \n",
       "..                ...                ...              ...   \n",
       "564         111.00000            0.11590          0.24390   \n",
       "565           0.09780            0.10340        144.00000   \n",
       "566           0.08455            0.10230          0.09251   \n",
       "567           0.11780          277.00000          0.35140   \n",
       "568           0.05263            0.04362          0.00000   \n",
       "\n",
       "     concave_points_mean   symmetry_mean   fractal_dimension_mean  ...  \\\n",
       "0                0.14710          0.2419                  0.07871  ...   \n",
       "1                0.07017          0.1812                  0.05667  ...   \n",
       "2                0.12790          0.2069                  0.05999  ...   \n",
       "3                0.10520          0.2597                  0.09744  ...   \n",
       "4                0.10430          0.1809                  0.05883  ...   \n",
       "..                   ...             ...                      ...  ...   \n",
       "564              0.13890          0.1726                  0.05623  ...   \n",
       "565              0.09791          0.1752                  0.05533  ...   \n",
       "566              0.05302        159.0000                  0.05648  ...   \n",
       "567            152.00000          0.2397                  0.07016  ...   \n",
       "568              0.00000          0.1587                  0.05884  ...   \n",
       "\n",
       "      radius_worst   texture_worst   perimeter_worst   area_worst  \\\n",
       "0            25.38           17.33            184.60       2019.0   \n",
       "1            24.99           23.41            158.80       1956.0   \n",
       "2            23.57           25.53            152.50       1709.0   \n",
       "3            14.91           26.50             98.87        567.7   \n",
       "4            22.54           16.67            152.20       1575.0   \n",
       "..             ...             ...               ...          ...   \n",
       "564          25.45           26.40            166.10       2027.0   \n",
       "565          23.69           38.25            155.00       1731.0   \n",
       "566          18.98           34.12            126.70       1124.0   \n",
       "567          25.74           39.42            184.60       1821.0   \n",
       "568        9456.00           30.37             59.16        268.6   \n",
       "\n",
       "      smoothness_worst   compactness_worst   concavity_worst  \\\n",
       "0              0.16220             0.66560            0.7119   \n",
       "1              0.12380             0.18660            0.2416   \n",
       "2              0.14440             0.42450            0.4504   \n",
       "3              0.20980             0.86630            0.6869   \n",
       "4              0.13740           205.00000            0.4000   \n",
       "..                 ...                 ...               ...   \n",
       "564          141.00000             0.21130            0.4107   \n",
       "565            0.11660             0.19220            0.3215   \n",
       "566            0.11390             0.30940            0.3403   \n",
       "567          165.00000             0.86810            0.9387   \n",
       "568            0.08996             0.06444            0.0000   \n",
       "\n",
       "      concave_points_worst   symmetry_worst   fractal_dimension_worst  \n",
       "0                   0.2654           0.4601                   0.11890  \n",
       "1                 186.0000         275.0000                   0.08902  \n",
       "2                 243.0000           0.3613                   0.08758  \n",
       "3                   0.2575           0.6638                 173.00000  \n",
       "4                   0.1625           0.2364                   0.07678  \n",
       "..                     ...              ...                       ...  \n",
       "564                 0.2216         206.0000                   0.07115  \n",
       "565                 0.1628           0.2572                   0.06637  \n",
       "566                 0.1418           0.2218                   0.07820  \n",
       "567               265.0000           0.4087                 124.00000  \n",
       "568                 0.0000           0.2871                   0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features\n",
    "X = pd.read_csv('../data/breast+cancer+wisconsin+diagnostic/x_bcwd.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "564  0\n",
       "565  0\n",
       "566  0\n",
       "567  0\n",
       "568  1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes\n",
    "y = pd.read_csv('../data/breast+cancer+wisconsin+diagnostic/y_bcwd.csv')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 1), (143, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define hidden layers\n",
    "\n",
    "30 (input) + 1 (output) = 15.5 ~= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = Sequential([\n",
    "    tf.keras.layers.InputLayer(shape = (30,)),\n",
    "    tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer='random_uniform'),\n",
    "    tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer='random_uniform'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neurons of input layer: 30\n",
    "# neurons of hidden layer: 16\n",
    "# total params: 496\n",
    "# to know how bias units\n",
    "int((496 - (30*16))/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 918us/step - binary_accuracy: 0.6591 - loss: 0.7706 \n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - binary_accuracy: 0.7701 - loss: 0.4850\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.7169 - loss: 0.5576\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - binary_accuracy: 0.7568 - loss: 0.5925\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.7845 - loss: 0.4981\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - binary_accuracy: 0.7731 - loss: 0.6895\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - binary_accuracy: 0.8341 - loss: 0.3885\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.8471 - loss: 0.4239\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - binary_accuracy: 0.7914 - loss: 0.4964\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8144 - loss: 0.4379\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - binary_accuracy: 0.8288 - loss: 0.5565\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - binary_accuracy: 0.8269 - loss: 0.4849\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - binary_accuracy: 0.7346 - loss: 0.6554\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - binary_accuracy: 0.8445 - loss: 0.3738\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.8432 - loss: 0.4480\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - binary_accuracy: 0.8227 - loss: 0.5051\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - binary_accuracy: 0.8154 - loss: 0.5370\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8349 - loss: 0.4852\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.7948 - loss: 0.4901\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8404 - loss: 0.4077\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.8613 - loss: 0.3305\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8180 - loss: 0.6003\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8823 - loss: 0.6129\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8688 - loss: 0.4363\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.8437 - loss: 0.4778\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - binary_accuracy: 0.8414 - loss: 0.6943\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - binary_accuracy: 0.8614 - loss: 0.4612\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - binary_accuracy: 0.7931 - loss: 0.7348\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.7807 - loss: 0.6743\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - binary_accuracy: 0.8816 - loss: 0.3606\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - binary_accuracy: 0.8717 - loss: 0.3793\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - binary_accuracy: 0.8325 - loss: 0.4589\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - binary_accuracy: 0.7865 - loss: 0.7757\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - binary_accuracy: 0.8619 - loss: 0.4745\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - binary_accuracy: 0.8956 - loss: 0.3540\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.8310 - loss: 0.7909\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - binary_accuracy: 0.8527 - loss: 0.4481\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - binary_accuracy: 0.8673 - loss: 0.3415\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - binary_accuracy: 0.8466 - loss: 0.5650\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - binary_accuracy: 0.8037 - loss: 0.6906\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - binary_accuracy: 0.8397 - loss: 0.5048\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - binary_accuracy: 0.8535 - loss: 0.4472\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - binary_accuracy: 0.8360 - loss: 0.4994\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8016 - loss: 0.5740\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - binary_accuracy: 0.8371 - loss: 0.4098\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - binary_accuracy: 0.8666 - loss: 0.4400\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8511 - loss: 0.5312\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - binary_accuracy: 0.8298 - loss: 0.5641\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - binary_accuracy: 0.8525 - loss: 0.4355\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - binary_accuracy: 0.8697 - loss: 0.3856\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - binary_accuracy: 0.8246 - loss: 0.4151\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - binary_accuracy: 0.8665 - loss: 0.3790\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8448 - loss: 0.6999\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8935 - loss: 0.4363\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - binary_accuracy: 0.8720 - loss: 0.4586\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.7891 - loss: 0.5653   \n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - binary_accuracy: 0.8737 - loss: 0.4156\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - binary_accuracy: 0.8804 - loss: 0.5946\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - binary_accuracy: 0.8679 - loss: 0.4896\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 705us/step - binary_accuracy: 0.8219 - loss: 0.6123\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8599 - loss: 0.4134\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - binary_accuracy: 0.8919 - loss: 0.4316\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - binary_accuracy: 0.8442 - loss: 0.4023\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - binary_accuracy: 0.8506 - loss: 0.5197\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 740us/step - binary_accuracy: 0.8604 - loss: 0.4650\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.8590 - loss: 0.4367\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8489 - loss: 0.4122\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8986 - loss: 0.3382 \n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - binary_accuracy: 0.9115 - loss: 0.2705\n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8370 - loss: 0.4939\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 692us/step - binary_accuracy: 0.8594 - loss: 0.5295\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8811 - loss: 0.4342\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.8399 - loss: 0.4631\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8148 - loss: 0.4990\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - binary_accuracy: 0.8481 - loss: 0.4925\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.7960 - loss: 0.6919\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 727us/step - binary_accuracy: 0.8594 - loss: 0.4199\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 715us/step - binary_accuracy: 0.8204 - loss: 0.5423\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 739us/step - binary_accuracy: 0.8689 - loss: 0.5778\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - binary_accuracy: 0.8244 - loss: 0.6351\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.8075 - loss: 0.5357\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.8307 - loss: 0.6068\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - binary_accuracy: 0.7963 - loss: 0.7988\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - binary_accuracy: 0.8008 - loss: 0.6504\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - binary_accuracy: 0.8204 - loss: 0.6679\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - binary_accuracy: 0.8614 - loss: 0.4871\n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - binary_accuracy: 0.8549 - loss: 0.5511\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - binary_accuracy: 0.8100 - loss: 0.6822\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.8169 - loss: 0.7462\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - binary_accuracy: 0.8290 - loss: 0.8134\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.8559 - loss: 0.5590\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - binary_accuracy: 0.8304 - loss: 0.6123\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - binary_accuracy: 0.8062 - loss: 0.6998\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - binary_accuracy: 0.8303 - loss: 0.5610\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - binary_accuracy: 0.8308 - loss: 0.5774\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - binary_accuracy: 0.8040 - loss: 0.8498\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8834 - loss: 0.4160 \n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - binary_accuracy: 0.8332 - loss: 0.7134\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 813us/step - binary_accuracy: 0.8544 - loss: 0.4710\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 728us/step - binary_accuracy: 0.8470 - loss: 0.4504\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x243624ed160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.fit(X_train, y_train, batch_size = 10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-4.61120903e-03,  1.38041284e-03, -1.66310832e-01,\n",
       "          1.77464768e-01,  2.94084772e-02,  5.67338988e-02,\n",
       "         -4.34834734e-02,  1.02347799e-01,  7.40257204e-02,\n",
       "         -6.48050103e-04, -2.36145165e-02, -8.81966129e-02,\n",
       "         -3.45995016e-02, -8.48519132e-02, -1.71790123e-02,\n",
       "         -4.16594625e-01],\n",
       "        [ 5.80472238e-02, -2.18461249e-02, -3.85459989e-01,\n",
       "          1.11627370e-01,  5.16527779e-02,  2.13570073e-01,\n",
       "          2.98384912e-02,  7.24022314e-02,  1.53154030e-01,\n",
       "         -4.70278487e-02,  3.53280194e-02, -1.02780841e-01,\n",
       "         -7.90628865e-02, -5.85097149e-02,  4.15753648e-02,\n",
       "         -3.99877191e-01],\n",
       "        [ 4.05689739e-02, -2.38022774e-01, -5.68727851e-02,\n",
       "          1.01345748e-01,  5.87313510e-02,  2.10752919e-01,\n",
       "         -1.87069662e-02,  1.39423937e-01, -1.63895432e-02,\n",
       "         -1.67141916e-04, -1.26774773e-01,  2.74126902e-02,\n",
       "         -2.08885111e-02, -6.61556646e-02,  1.10344641e-01,\n",
       "          7.54726410e-04],\n",
       "        [-5.69579676e-02, -1.44221466e-02,  1.27720525e-02,\n",
       "          9.64507535e-02, -1.03851020e-01, -1.75902154e-03,\n",
       "         -2.91658994e-02,  7.08998144e-02, -2.01357808e-02,\n",
       "         -6.45164475e-02, -1.63306128e-02, -2.58813761e-02,\n",
       "          1.68022569e-02, -3.44900116e-02, -7.04363659e-02,\n",
       "          1.17436714e-01],\n",
       "        [-7.39374012e-02,  8.08304399e-02, -1.13053210e-01,\n",
       "         -6.89118654e-02,  7.30022117e-02,  5.68196438e-02,\n",
       "          6.81450218e-03,  7.59079158e-02,  3.75433005e-02,\n",
       "          8.37111101e-03,  1.74624562e-01, -4.63023447e-02,\n",
       "          2.66573927e-03,  8.23555812e-02,  1.33227240e-02,\n",
       "         -2.24331006e-01],\n",
       "        [-3.75849474e-03, -1.07971877e-02, -3.78555208e-02,\n",
       "          6.88172281e-02, -1.40772998e-01, -3.53311710e-02,\n",
       "         -4.18473370e-02,  1.95092726e-02,  1.22302219e-01,\n",
       "          5.40235173e-03, -4.37437557e-02, -5.08901067e-02,\n",
       "          2.12040115e-02, -2.86012776e-02,  6.69784173e-02,\n",
       "         -9.55676734e-02],\n",
       "        [ 2.85230838e-02,  1.04436956e-01, -4.92789298e-02,\n",
       "         -1.60117447e-01,  2.76869778e-02, -7.46816024e-02,\n",
       "         -2.63487343e-02, -5.39606139e-02,  4.69464511e-02,\n",
       "         -9.11192149e-02,  7.92378262e-02, -5.53605556e-02,\n",
       "         -7.04135001e-02,  2.35494167e-01,  3.86372954e-02,\n",
       "         -3.10647544e-02],\n",
       "        [-1.45636573e-01,  6.86103180e-02,  1.03709243e-01,\n",
       "         -3.12732190e-01, -1.08302891e-01,  8.55478942e-02,\n",
       "         -4.18354645e-02,  8.69842172e-02, -8.36771503e-02,\n",
       "         -7.90648162e-03, -6.26034513e-02,  1.38635570e-02,\n",
       "         -2.26217532e-03, -5.99411577e-02,  6.89953938e-02,\n",
       "          8.64390433e-02],\n",
       "        [-6.63904846e-02, -1.54424325e-01,  1.03821941e-01,\n",
       "          6.61571994e-02,  9.18595344e-02,  1.75265223e-01,\n",
       "          1.93951279e-03,  5.87901622e-02, -8.01047757e-02,\n",
       "          1.45494966e-02, -1.39660656e-01,  1.01393787e-03,\n",
       "         -3.19376662e-02,  2.98531353e-03, -7.72495419e-02,\n",
       "          1.59786656e-01],\n",
       "        [ 2.96714038e-01,  1.21606383e-02, -2.85671860e-01,\n",
       "          1.64860994e-01, -3.09666783e-01,  1.87695980e-01,\n",
       "         -5.31022623e-03, -1.15814060e-01, -1.81158647e-01,\n",
       "         -5.69433458e-02, -2.49690264e-01, -3.83842550e-02,\n",
       "         -6.55917153e-02,  6.09287955e-02,  3.77711117e-01,\n",
       "          4.78655308e-01],\n",
       "        [ 2.25881353e-01, -1.04488499e-01, -7.57244751e-02,\n",
       "          4.10263874e-02,  3.41717042e-02,  1.76332846e-01,\n",
       "         -3.31516750e-02,  7.43721202e-02,  6.40950128e-02,\n",
       "          1.57088344e-03, -8.20149928e-02, -2.60872357e-02,\n",
       "         -1.70733538e-02, -7.62340501e-02,  4.80788499e-02,\n",
       "         -7.71908462e-02],\n",
       "        [ 1.51319401e-02, -8.35061967e-02,  2.34477043e-01,\n",
       "         -5.01829572e-02, -7.95658380e-02,  8.18732753e-03,\n",
       "         -2.37234719e-02, -4.03149948e-02, -1.63183108e-01,\n",
       "          3.25477007e-03, -1.43607333e-01,  3.93856727e-02,\n",
       "          9.34099685e-03, -9.65901837e-02,  9.07950290e-03,\n",
       "         -7.69454911e-02],\n",
       "        [-1.04973920e-01,  8.75990167e-02,  6.47714734e-02,\n",
       "          1.02829203e-01, -6.65329248e-02, -1.13242477e-01,\n",
       "         -4.75754850e-02,  5.25089987e-02,  5.29032126e-02,\n",
       "          1.53403985e-03,  8.79645944e-02, -3.75437783e-03,\n",
       "         -6.53079338e-03,  9.51716602e-02, -3.57237309e-02,\n",
       "          6.29512295e-02],\n",
       "        [ 4.13060468e-03,  3.33244354e-01, -5.08769572e-01,\n",
       "          2.00471640e-01, -1.25042880e-02,  2.07925156e-01,\n",
       "         -4.44051400e-02,  3.32387894e-01,  6.25723243e-01,\n",
       "         -1.00925229e-02,  7.90463760e-02, -2.67627209e-01,\n",
       "         -1.13662586e-01, -2.49427378e-01, -7.75139639e-03,\n",
       "         -1.03727937e+00],\n",
       "        [-9.73775983e-04, -2.12110400e-01, -3.42242926e-01,\n",
       "          1.03460036e-01, -4.18775380e-02, -2.56911274e-02,\n",
       "         -3.29975709e-02, -3.98647711e-02,  1.22521140e-01,\n",
       "          1.72676146e-02,  2.05750521e-02, -5.53259999e-02,\n",
       "         -1.10265195e-01, -5.64843491e-02, -3.70887816e-02,\n",
       "         -1.69968694e-01],\n",
       "        [-1.73948586e-01,  3.19085926e-01,  1.19682383e-02,\n",
       "         -2.40336850e-01,  1.21662237e-01,  6.27943948e-02,\n",
       "         -3.49831693e-02,  1.65178716e-01,  5.08734118e-03,\n",
       "          4.35770005e-02,  5.47564402e-02, -4.61705448e-03,\n",
       "          1.53299756e-02, -3.47229950e-02,  8.53063092e-02,\n",
       "         -3.15840870e-01],\n",
       "        [ 1.18923187e-02, -1.26820534e-01, -2.99883872e-01,\n",
       "         -8.12469348e-02,  7.59566352e-02,  1.03644788e-01,\n",
       "          2.27327459e-02,  1.16876729e-01,  8.59975889e-02,\n",
       "         -2.01202426e-02,  3.98955755e-02, -5.59617579e-02,\n",
       "         -6.51988015e-02,  1.45624140e-02,  1.13986008e-01,\n",
       "         -2.99197823e-01],\n",
       "        [ 1.56826079e-02,  7.61924684e-02,  3.88335317e-01,\n",
       "          2.58493461e-02, -1.27150252e-01,  1.99477449e-02,\n",
       "         -1.27238743e-02,  2.05141082e-01, -2.63372242e-01,\n",
       "         -4.42704782e-02, -2.14656249e-01,  3.72865051e-02,\n",
       "         -3.76455262e-02,  8.13198835e-02,  4.39247526e-02,\n",
       "         -4.28895131e-02],\n",
       "        [ 2.33462173e-02,  5.71238203e-03, -4.78804022e-01,\n",
       "         -5.71721746e-03,  3.61742944e-01,  3.14200193e-01,\n",
       "          3.18869613e-02, -2.67348558e-01,  2.84899384e-01,\n",
       "          1.12466253e-02,  5.67350052e-02, -8.40111971e-02,\n",
       "         -3.42407189e-02,  2.00549066e-02, -3.46069485e-02,\n",
       "          1.11227356e-01],\n",
       "        [ 4.73414660e-02,  1.84936717e-01, -5.56132853e-01,\n",
       "         -4.92108837e-02,  8.59141629e-03,  6.57821596e-02,\n",
       "         -3.56004722e-02, -2.01552704e-01,  4.46246207e-01,\n",
       "         -5.67151383e-02,  3.59936506e-01, -1.63611099e-01,\n",
       "          2.65804096e-03,  1.95061296e-01,  6.22460321e-02,\n",
       "         -4.55002278e-01],\n",
       "        [-7.19717564e-03,  4.70317639e-02, -2.23118156e-01,\n",
       "          1.81986526e-01,  9.17991027e-02,  1.00217640e-01,\n",
       "         -4.27208804e-02,  1.87233850e-01,  1.72798485e-01,\n",
       "         -1.11706480e-02, -2.01766081e-02, -1.00402959e-01,\n",
       "         -2.61768736e-02, -1.29863918e-01, -1.42141543e-02,\n",
       "         -5.08523941e-01],\n",
       "        [ 6.21042475e-02, -3.41269188e-02, -4.32572603e-01,\n",
       "          2.59209853e-02,  1.76200867e-01,  2.45224923e-01,\n",
       "          4.16564383e-02,  1.06235202e-02,  2.04353377e-01,\n",
       "         -6.11237921e-02,  4.14939001e-02, -1.46703362e-01,\n",
       "         -2.51950137e-02, -4.63159829e-02,  3.28895599e-02,\n",
       "         -4.04451877e-01],\n",
       "        [ 9.27178115e-02, -8.87197182e-02, -6.60395026e-02,\n",
       "          3.06725204e-02,  5.14143035e-02,  2.58336663e-01,\n",
       "         -2.18220111e-02,  1.40387416e-01,  2.87405718e-02,\n",
       "         -1.12406118e-02, -1.18633300e-01,  2.11195857e-03,\n",
       "         -1.14725880e-01,  3.43647855e-03,  4.51735258e-02,\n",
       "         -2.37687007e-02],\n",
       "        [-6.45751730e-02,  1.11411326e-01, -1.14055008e-01,\n",
       "          3.16149890e-02, -7.55089661e-03,  7.51649961e-02,\n",
       "         -1.70415752e-02,  1.37729466e-01,  1.50736541e-01,\n",
       "          1.19104227e-02,  1.17264912e-01, -8.89634266e-02,\n",
       "         -7.22523928e-02, -2.15566996e-02, -4.77771740e-03,\n",
       "         -1.73846297e-02],\n",
       "        [-7.95966536e-02, -1.22850917e-01, -8.14725608e-02,\n",
       "         -1.45504087e-01,  1.37231261e-01,  2.40733415e-01,\n",
       "          3.75110991e-02,  2.12567318e-02, -5.82200587e-02,\n",
       "         -3.31780384e-03,  8.96515325e-03,  7.46018160e-03,\n",
       "         -1.62312500e-02,  1.81637034e-01, -1.20168008e-01,\n",
       "          1.60882533e-01],\n",
       "        [-1.26999855e-01, -1.72854468e-01, -1.77353010e-01,\n",
       "         -3.02153528e-01,  8.54666308e-02,  3.22923273e-01,\n",
       "         -3.12194824e-02,  2.32908905e-01,  4.01555002e-02,\n",
       "         -9.58672911e-03, -1.43477991e-01, -6.20752806e-03,\n",
       "         -5.76162487e-02, -9.18935314e-02, -4.81244959e-02,\n",
       "          1.62348732e-01],\n",
       "        [-7.30284378e-02, -1.41511768e-01,  1.62840173e-01,\n",
       "         -1.08991668e-01,  8.78058970e-02,  2.94427574e-01,\n",
       "          1.66542456e-03,  1.16519541e-01, -8.01996887e-02,\n",
       "         -3.37264203e-02, -1.11560807e-01, -2.83157527e-02,\n",
       "          2.93939877e-02,  1.45641625e-01, -6.17212243e-02,\n",
       "          2.26422191e-01],\n",
       "        [ 1.61758557e-01, -6.04017787e-02, -1.45129576e-01,\n",
       "         -2.73740083e-01,  2.90874839e-01,  2.88826972e-01,\n",
       "          4.52212431e-02,  6.26440868e-02,  2.18225837e-01,\n",
       "         -6.89523965e-02, -1.52583066e-02, -8.33740532e-02,\n",
       "         -6.80543259e-02, -1.11561306e-01, -8.63499194e-02,\n",
       "         -3.41709971e-01],\n",
       "        [-5.73198423e-02, -6.30947649e-02, -1.36872917e-01,\n",
       "         -2.29751214e-01,  3.31346393e-02,  7.03899339e-02,\n",
       "          2.48205774e-02,  5.42878080e-03, -1.37659302e-02,\n",
       "         -1.83870886e-02, -8.78258124e-02, -4.18696832e-03,\n",
       "         -8.96991417e-03, -3.18028256e-02, -4.16308232e-02,\n",
       "          1.06328011e-01],\n",
       "        [ 2.54422370e-02,  3.67724717e-01, -3.82309020e-01,\n",
       "          9.15056840e-02,  1.44198895e-01,  3.35957468e-01,\n",
       "          4.52917702e-02, -1.16180107e-01,  4.56072569e-01,\n",
       "         -2.74759978e-02,  3.15728545e-01, -1.97725505e-01,\n",
       "         -1.88956987e-02,  1.63044870e-01, -5.66415749e-02,\n",
       "         -5.11450768e-01]], dtype=float32),\n",
       " array([-0.03987174, -0.411822  ,  0.20476918,  0.45487872, -0.20289852,\n",
       "        -0.13662367,  0.        ,  0.01434431, -0.18087235, -0.05026373,\n",
       "        -0.14719047,  0.0497723 , -0.04811828, -0.03803481, -0.01550978,\n",
       "         0.1284409 ], dtype=float32)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights0 = neural_network.layers[0].get_weights()\n",
    "weights0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # we can get weights of the other layers too \n",
    "len(weights0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 16)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights first position: neuron weights\n",
    "#weights second position: bias weights\n",
    "len(weights0[0]), len(weights0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    }
   ],
   "source": [
    "predict = neural_network.predict(X_test)\n",
    "predict = predict > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "151  1\n",
       "256  0\n",
       "315  1\n",
       "270  1\n",
       "411  1\n",
       "..  ..\n",
       "461  0\n",
       "567  0\n",
       "176  1\n",
       "53   0\n",
       "338  1\n",
       "\n",
       "[143 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we should compare to the data of y_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6783216783216783"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[56,  4],\n",
       "       [42, 41]], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 15)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#successes  x errors \n",
    "44+84,1+14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.6840 - loss: 1.3476  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.2509663105010986, 0.6783216595649719]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it returns an array with error and accuracy values\n",
    "neural_network.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
