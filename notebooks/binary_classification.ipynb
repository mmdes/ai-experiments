{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification \n",
    "\n",
    "Database: https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2'"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave_points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>fractal_dimension_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave_points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>186.0000</td>\n",
       "      <td>275.0000</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>243.0000</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>173.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>198.00000</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>205.00000</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>111.00000</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>25.45</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>141.00000</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>206.0000</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>144.00000</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>23.69</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>159.0000</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>18.98</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>277.00000</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>152.00000</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>25.74</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>165.00000</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>265.0000</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>124.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>9456.00</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      radius_mean   texture_mean   perimeter_mean   area_mean  \\\n",
       "0           17.99          10.38           122.80      1001.0   \n",
       "1           20.57          17.77           132.90      1326.0   \n",
       "2           19.69          21.25           130.00      1203.0   \n",
       "3           11.42          20.38            77.58       386.1   \n",
       "4           20.29          14.34           135.10      1297.0   \n",
       "..            ...            ...              ...         ...   \n",
       "564         21.56          22.39           142.00      1479.0   \n",
       "565         20.13          28.25           131.20      1261.0   \n",
       "566         16.60          28.08           108.30       858.1   \n",
       "567         20.60          29.33           140.10      1265.0   \n",
       "568          7.76          24.54            47.92       181.0   \n",
       "\n",
       "      smoothness_mean   compactness_mean   concavity_mean  \\\n",
       "0             0.11840            0.27760          0.30010   \n",
       "1             0.08474            0.07864          0.08690   \n",
       "2             0.10960            0.15990          0.19740   \n",
       "3             0.14250            0.28390          0.24140   \n",
       "4             0.10030            0.13280        198.00000   \n",
       "..                ...                ...              ...   \n",
       "564         111.00000            0.11590          0.24390   \n",
       "565           0.09780            0.10340        144.00000   \n",
       "566           0.08455            0.10230          0.09251   \n",
       "567           0.11780          277.00000          0.35140   \n",
       "568           0.05263            0.04362          0.00000   \n",
       "\n",
       "     concave_points_mean   symmetry_mean   fractal_dimension_mean  ...  \\\n",
       "0                0.14710          0.2419                  0.07871  ...   \n",
       "1                0.07017          0.1812                  0.05667  ...   \n",
       "2                0.12790          0.2069                  0.05999  ...   \n",
       "3                0.10520          0.2597                  0.09744  ...   \n",
       "4                0.10430          0.1809                  0.05883  ...   \n",
       "..                   ...             ...                      ...  ...   \n",
       "564              0.13890          0.1726                  0.05623  ...   \n",
       "565              0.09791          0.1752                  0.05533  ...   \n",
       "566              0.05302        159.0000                  0.05648  ...   \n",
       "567            152.00000          0.2397                  0.07016  ...   \n",
       "568              0.00000          0.1587                  0.05884  ...   \n",
       "\n",
       "      radius_worst   texture_worst   perimeter_worst   area_worst  \\\n",
       "0            25.38           17.33            184.60       2019.0   \n",
       "1            24.99           23.41            158.80       1956.0   \n",
       "2            23.57           25.53            152.50       1709.0   \n",
       "3            14.91           26.50             98.87        567.7   \n",
       "4            22.54           16.67            152.20       1575.0   \n",
       "..             ...             ...               ...          ...   \n",
       "564          25.45           26.40            166.10       2027.0   \n",
       "565          23.69           38.25            155.00       1731.0   \n",
       "566          18.98           34.12            126.70       1124.0   \n",
       "567          25.74           39.42            184.60       1821.0   \n",
       "568        9456.00           30.37             59.16        268.6   \n",
       "\n",
       "      smoothness_worst   compactness_worst   concavity_worst  \\\n",
       "0              0.16220             0.66560            0.7119   \n",
       "1              0.12380             0.18660            0.2416   \n",
       "2              0.14440             0.42450            0.4504   \n",
       "3              0.20980             0.86630            0.6869   \n",
       "4              0.13740           205.00000            0.4000   \n",
       "..                 ...                 ...               ...   \n",
       "564          141.00000             0.21130            0.4107   \n",
       "565            0.11660             0.19220            0.3215   \n",
       "566            0.11390             0.30940            0.3403   \n",
       "567          165.00000             0.86810            0.9387   \n",
       "568            0.08996             0.06444            0.0000   \n",
       "\n",
       "      concave_points_worst   symmetry_worst   fractal_dimension_worst  \n",
       "0                   0.2654           0.4601                   0.11890  \n",
       "1                 186.0000         275.0000                   0.08902  \n",
       "2                 243.0000           0.3613                   0.08758  \n",
       "3                   0.2575           0.6638                 173.00000  \n",
       "4                   0.1625           0.2364                   0.07678  \n",
       "..                     ...              ...                       ...  \n",
       "564                 0.2216         206.0000                   0.07115  \n",
       "565                 0.1628           0.2572                   0.06637  \n",
       "566                 0.1418           0.2218                   0.07820  \n",
       "567               265.0000           0.4087                 124.00000  \n",
       "568                 0.0000           0.2871                   0.07039  \n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# features\n",
    "X = pd.read_csv('../data/breast+cancer+wisconsin+diagnostic/x_bcwd.csv')\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 30)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    0\n",
       "1    0\n",
       "2    0\n",
       "3    0\n",
       "4    0\n",
       "..  ..\n",
       "564  0\n",
       "565  0\n",
       "566  0\n",
       "567  0\n",
       "568  1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes\n",
    "y = pd.read_csv('../data/breast+cancer+wisconsin+diagnostic/y_bcwd.csv')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.1'"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 30), (143, 30))"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((426, 1), (143, 1))"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.17.0'"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To define hidden layers\n",
    "\n",
    "30 (input) + 1 (output) = 15.5 ~= 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = Sequential([\n",
    "    tf.keras.layers.InputLayer(shape = (30,)),\n",
    "    tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer='random_uniform'),\n",
    "    tf.keras.layers.Dense(units=16, activation = 'relu', kernel_initializer='random_uniform'),\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">272</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_24 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_25 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m272\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_26 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">785</span> (3.07 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m785\u001b[0m (3.07 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neural_network.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neurons of input layer: 30\n",
    "# neurons of hidden layer: 16\n",
    "# total params: 496\n",
    "# to know how bias units\n",
    "int((496 - (30*16))/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipvalue=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['binary_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822us/step - binary_accuracy: 0.5358 - loss: 1.2887 \n",
      "Epoch 2/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - binary_accuracy: 0.7232 - loss: 0.5298\n",
      "Epoch 3/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 703us/step - binary_accuracy: 0.7391 - loss: 0.5502\n",
      "Epoch 4/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8252 - loss: 0.4616\n",
      "Epoch 5/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.7804 - loss: 0.4876\n",
      "Epoch 6/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8262 - loss: 0.4382\n",
      "Epoch 7/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 762us/step - binary_accuracy: 0.8209 - loss: 0.4592\n",
      "Epoch 8/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - binary_accuracy: 0.7823 - loss: 0.4698\n",
      "Epoch 9/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - binary_accuracy: 0.8438 - loss: 0.3974\n",
      "Epoch 10/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8249 - loss: 0.4076\n",
      "Epoch 11/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8254 - loss: 0.3991\n",
      "Epoch 12/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.7926 - loss: 0.5112\n",
      "Epoch 13/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8361 - loss: 0.5233\n",
      "Epoch 14/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8022 - loss: 0.5044\n",
      "Epoch 15/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8280 - loss: 0.4534\n",
      "Epoch 16/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - binary_accuracy: 0.8119 - loss: 0.5472\n",
      "Epoch 17/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8007 - loss: 0.6462\n",
      "Epoch 18/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - binary_accuracy: 0.8052 - loss: 0.6533\n",
      "Epoch 19/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8082 - loss: 0.5276\n",
      "Epoch 20/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8476 - loss: 0.6137\n",
      "Epoch 21/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8484 - loss: 0.4968\n",
      "Epoch 22/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.7723 - loss: 0.8241\n",
      "Epoch 23/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8335 - loss: 0.5358\n",
      "Epoch 24/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8453 - loss: 0.5983\n",
      "Epoch 25/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8189 - loss: 0.5034\n",
      "Epoch 26/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 655us/step - binary_accuracy: 0.8292 - loss: 0.6198\n",
      "Epoch 27/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8215 - loss: 0.5095\n",
      "Epoch 28/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8052 - loss: 0.4800\n",
      "Epoch 29/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8821 - loss: 0.3365\n",
      "Epoch 30/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8501 - loss: 0.5114\n",
      "Epoch 31/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - binary_accuracy: 0.8884 - loss: 0.3514\n",
      "Epoch 32/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.7999 - loss: 0.7749\n",
      "Epoch 33/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8242 - loss: 0.4794\n",
      "Epoch 34/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8727 - loss: 0.3419\n",
      "Epoch 35/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8032 - loss: 0.5525\n",
      "Epoch 36/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8685 - loss: 0.4135\n",
      "Epoch 37/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - binary_accuracy: 0.8560 - loss: 0.5714\n",
      "Epoch 38/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8361 - loss: 0.5973\n",
      "Epoch 39/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8310 - loss: 0.6458\n",
      "Epoch 40/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8046 - loss: 0.5134\n",
      "Epoch 41/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8464 - loss: 0.4759\n",
      "Epoch 42/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8252 - loss: 0.5689\n",
      "Epoch 43/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.7991 - loss: 0.7125\n",
      "Epoch 44/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8780 - loss: 0.4478\n",
      "Epoch 45/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8443 - loss: 0.5264\n",
      "Epoch 46/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8416 - loss: 0.5312\n",
      "Epoch 47/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8153 - loss: 0.5857\n",
      "Epoch 48/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8154 - loss: 0.6969\n",
      "Epoch 49/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - binary_accuracy: 0.8215 - loss: 0.7236\n",
      "Epoch 50/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8542 - loss: 0.5442\n",
      "Epoch 51/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8294 - loss: 0.6233\n",
      "Epoch 52/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - binary_accuracy: 0.8015 - loss: 0.9110\n",
      "Epoch 53/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8935 - loss: 0.5093\n",
      "Epoch 54/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.7734 - loss: 0.8689\n",
      "Epoch 55/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8220 - loss: 0.7898\n",
      "Epoch 56/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - binary_accuracy: 0.8673 - loss: 0.5278\n",
      "Epoch 57/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8701 - loss: 0.5118\n",
      "Epoch 58/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8038 - loss: 0.5790\n",
      "Epoch 59/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.7925 - loss: 0.8404\n",
      "Epoch 60/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8799 - loss: 0.3930\n",
      "Epoch 61/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.7896 - loss: 0.7280\n",
      "Epoch 62/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8904 - loss: 0.4516\n",
      "Epoch 63/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8566 - loss: 0.5666\n",
      "Epoch 64/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8650 - loss: 0.6071\n",
      "Epoch 65/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8253 - loss: 0.7508\n",
      "Epoch 66/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8123 - loss: 0.7433\n",
      "Epoch 67/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8551 - loss: 0.6049\n",
      "Epoch 68/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8247 - loss: 0.5877\n",
      "Epoch 69/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8746 - loss: 0.5820 \n",
      "Epoch 70/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8343 - loss: 0.6429\n",
      "Epoch 71/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8624 - loss: 0.6555\n",
      "Epoch 72/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 678us/step - binary_accuracy: 0.8376 - loss: 0.8008\n",
      "Epoch 73/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8601 - loss: 0.8013\n",
      "Epoch 74/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8435 - loss: 0.5738\n",
      "Epoch 75/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - binary_accuracy: 0.8677 - loss: 0.4670\n",
      "Epoch 76/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8442 - loss: 0.6550\n",
      "Epoch 77/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.7902 - loss: 0.7118\n",
      "Epoch 78/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8827 - loss: 0.4339\n",
      "Epoch 79/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8670 - loss: 0.6138\n",
      "Epoch 80/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8214 - loss: 1.0055\n",
      "Epoch 81/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8659 - loss: 0.6309\n",
      "Epoch 82/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8232 - loss: 0.6785\n",
      "Epoch 83/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8205 - loss: 1.0458\n",
      "Epoch 84/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8194 - loss: 0.8582\n",
      "Epoch 85/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8489 - loss: 0.7527\n",
      "Epoch 86/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8665 - loss: 0.5803 \n",
      "Epoch 87/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 726us/step - binary_accuracy: 0.8319 - loss: 0.6706\n",
      "Epoch 88/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8007 - loss: 1.5499\n",
      "Epoch 89/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - binary_accuracy: 0.8705 - loss: 0.3747\n",
      "Epoch 90/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8536 - loss: 0.6733\n",
      "Epoch 91/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8374 - loss: 0.5582\n",
      "Epoch 92/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8446 - loss: 0.6648\n",
      "Epoch 93/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8301 - loss: 1.0504\n",
      "Epoch 94/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - binary_accuracy: 0.8227 - loss: 0.8798\n",
      "Epoch 95/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - binary_accuracy: 0.8602 - loss: 0.7969\n",
      "Epoch 96/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 709us/step - binary_accuracy: 0.8570 - loss: 0.5975\n",
      "Epoch 97/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - binary_accuracy: 0.8582 - loss: 0.6704\n",
      "Epoch 98/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - binary_accuracy: 0.8458 - loss: 0.8029\n",
      "Epoch 99/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 738us/step - binary_accuracy: 0.8472 - loss: 0.7907\n",
      "Epoch 100/100\n",
      "\u001b[1m43/43\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - binary_accuracy: 0.8027 - loss: 1.5195\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x293524fc560>"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neural_network.fit(X_train, y_train, batch_size = 10, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-4.36681837e-01, -3.97778451e-02,  1.23185284e-01,\n",
       "         -6.18574023e-02, -4.52393144e-02, -2.09609672e-01,\n",
       "         -3.13560724e-01, -1.98467940e-01,  1.46434918e-01,\n",
       "         -4.44828309e-02,  5.22528328e-02, -5.46321981e-02,\n",
       "         -4.78420742e-02, -1.73293017e-02, -4.17105317e-01,\n",
       "         -1.88410148e-01],\n",
       "        [-4.93198633e-01,  5.11593595e-02,  5.52775897e-02,\n",
       "          3.60841341e-02, -2.25193333e-02, -1.72567338e-01,\n",
       "         -3.95400852e-01, -1.48887858e-01,  1.09741986e-01,\n",
       "         -4.27987762e-02,  5.17708547e-02, -1.08213723e-02,\n",
       "         -2.93512866e-02, -4.20351066e-02, -3.72989267e-01,\n",
       "         -1.13578230e-01],\n",
       "        [-2.97589600e-01, -2.17286125e-02, -1.22094035e-01,\n",
       "         -3.18641476e-02, -4.19775443e-03,  2.41421182e-02,\n",
       "         -1.54642895e-01, -1.61970872e-02, -3.47303972e-02,\n",
       "         -5.13093583e-02, -5.37281409e-02, -6.65425882e-02,\n",
       "          1.95278861e-02, -3.58620984e-03, -5.42866923e-02,\n",
       "          1.18963905e-02],\n",
       "        [-1.81786511e-02,  5.69289401e-02, -1.18804229e-02,\n",
       "         -1.42241791e-02,  2.93991156e-03,  1.35783330e-01,\n",
       "         -2.90197711e-02,  1.00043841e-01, -8.79014954e-02,\n",
       "          3.38556729e-02, -5.39902449e-02, -2.29747351e-02,\n",
       "         -3.15359719e-02, -2.33262125e-02,  3.12537812e-02,\n",
       "          4.16910239e-02],\n",
       "        [-1.00620553e-01, -1.73985530e-02,  1.14519410e-01,\n",
       "         -5.95464855e-02,  2.54822392e-02, -2.38740630e-02,\n",
       "          4.65108231e-02, -1.19673841e-01, -4.51547615e-02,\n",
       "         -3.29595152e-03,  1.05672851e-01,  7.97291938e-03,\n",
       "          2.93258973e-03, -5.22575807e-03, -2.91352332e-01,\n",
       "         -1.12820566e-01],\n",
       "        [ 4.13549803e-02,  5.14717773e-03, -1.25393003e-01,\n",
       "         -3.50099653e-02,  2.94125993e-02, -6.16290420e-02,\n",
       "         -1.05606373e-02, -7.66643137e-02, -1.25231817e-01,\n",
       "         -1.17012616e-02,  8.20522383e-03, -9.57870297e-03,\n",
       "         -1.44841140e-02,  2.96063200e-02, -1.11962125e-01,\n",
       "         -1.58862129e-01],\n",
       "        [-1.08449101e-01,  1.40320078e-01,  1.74102616e-02,\n",
       "          2.42583500e-03, -4.36529070e-02, -2.52814651e-01,\n",
       "         -1.02767624e-01, -2.86098212e-01,  5.25410026e-02,\n",
       "          2.10018735e-02, -6.82678213e-03, -1.31405201e-02,\n",
       "         -3.46023415e-04,  1.63281877e-02, -5.67387082e-02,\n",
       "         -1.84165969e-01],\n",
       "        [ 1.01706028e-01, -7.27372244e-03, -5.01598120e-02,\n",
       "         -3.53340502e-03, -4.96825650e-02, -1.05503790e-01,\n",
       "          1.13504849e-01, -1.87418461e-01,  6.08148575e-02,\n",
       "         -9.90519114e-03,  2.08900496e-02,  1.31984288e-02,\n",
       "         -5.16706072e-02,  1.68115515e-02, -1.09834425e-01,\n",
       "         -1.76623002e-01],\n",
       "        [-4.99107130e-02, -6.45981655e-02,  4.93414029e-02,\n",
       "          3.60955149e-02, -1.13844322e-02,  7.34298602e-02,\n",
       "          1.21158235e-01, -9.07163918e-02,  3.35028321e-02,\n",
       "         -3.03598959e-02, -5.96621558e-02,  5.05244210e-02,\n",
       "          9.50744376e-03,  3.57624404e-02,  4.05168198e-02,\n",
       "          5.33870533e-02],\n",
       "        [-3.07366759e-01,  2.97247112e-01, -2.89957430e-02,\n",
       "         -1.30430907e-02, -2.71624923e-02,  6.18892908e-01,\n",
       "         -2.35512987e-01,  1.77101105e-01, -1.91701725e-01,\n",
       "          2.03200895e-02,  3.25277857e-02,  1.68019924e-02,\n",
       "          2.91377921e-02, -2.58956086e-02,  1.25523686e-01,\n",
       "          1.57404914e-01],\n",
       "        [-1.23076744e-01,  5.38758971e-02, -7.38902539e-02,\n",
       "         -4.86452170e-02, -3.02388500e-02,  4.12116833e-02,\n",
       "         -6.38962537e-02,  9.54412520e-02, -2.72258315e-02,\n",
       "          4.27093852e-04, -2.48463228e-02, -1.59914754e-02,\n",
       "         -2.36739144e-02, -4.31032740e-02, -2.05815211e-01,\n",
       "          1.60719212e-02],\n",
       "        [ 1.58843443e-01, -1.10524207e-01, -1.14768438e-01,\n",
       "         -1.92927243e-03, -8.14129366e-04,  2.00705957e-02,\n",
       "          1.80225566e-01, -2.31694803e-02, -7.97879845e-02,\n",
       "         -1.40417246e-02,  5.16899512e-04,  1.79754943e-02,\n",
       "         -2.93322969e-02, -5.46135940e-02, -1.49975508e-01,\n",
       "         -1.19399987e-01],\n",
       "        [ 4.37628590e-02,  1.16806947e-01,  4.48405370e-02,\n",
       "         -5.17263561e-02, -5.95918633e-02,  4.85583879e-02,\n",
       "          7.09952414e-02,  4.59859744e-02,  6.54284135e-02,\n",
       "         -5.97011000e-02,  9.93145281e-04, -4.45741462e-03,\n",
       "         -4.23430055e-02,  6.89970469e-03,  1.04061574e-01,\n",
       "          3.58038209e-02],\n",
       "        [-4.70437050e-01,  4.38330054e-01,  3.54398191e-01,\n",
       "         -2.21521519e-02, -5.00539131e-02, -6.78120315e-01,\n",
       "         -9.43117559e-01, -4.26430970e-01,  3.92292500e-01,\n",
       "         -5.22502549e-02,  1.97062761e-01, -1.15626872e-01,\n",
       "         -2.08291244e-02, -4.59154509e-02, -8.80750299e-01,\n",
       "         -5.97222567e-01],\n",
       "        [-4.74882871e-01, -1.27092317e-01,  6.14092909e-02,\n",
       "         -3.23638171e-02,  3.09661981e-02, -7.16075972e-02,\n",
       "         -3.75149280e-01, -3.69834341e-02,  5.89616448e-02,\n",
       "         -3.03702354e-02,  1.62599474e-01, -2.33253743e-03,\n",
       "         -4.55126502e-02, -2.02499349e-02, -4.48103577e-01,\n",
       "         -1.09668456e-01],\n",
       "        [-3.17212999e-01,  6.44928589e-02, -1.96676608e-02,\n",
       "         -3.55223902e-02, -3.08957528e-02, -3.83904248e-01,\n",
       "         -1.26892954e-01, -1.89784214e-01,  3.18093151e-01,\n",
       "          2.50083599e-02,  2.97220260e-01,  4.72051613e-02,\n",
       "         -4.24041739e-03, -3.30837071e-02, -3.23065341e-01,\n",
       "         -2.17470199e-01],\n",
       "        [ 2.03218222e-01, -1.47212148e-01, -1.35832086e-01,\n",
       "          1.65231358e-02,  1.09259021e-02,  7.27560371e-02,\n",
       "          3.14908981e-01, -7.90184829e-03, -1.69991791e-01,\n",
       "         -6.29494190e-02, -4.23881710e-02, -3.24015915e-02,\n",
       "         -3.59705649e-03, -5.19016311e-02, -7.49411881e-02,\n",
       "         -3.16023119e-02],\n",
       "        [ 1.83189929e-01, -1.81786537e-01, -1.22196466e-01,\n",
       "         -5.70124984e-02, -6.05909340e-03, -7.39840418e-02,\n",
       "          2.92704225e-01, -1.72438100e-01, -1.04689695e-01,\n",
       "         -3.93698290e-02,  9.37799960e-02,  1.77425239e-02,\n",
       "          3.68211493e-02,  1.19728725e-02, -7.70320967e-02,\n",
       "         -8.79793540e-02],\n",
       "        [-4.09192801e-01,  1.50807485e-01,  1.04743406e-01,\n",
       "          1.88120604e-02,  1.88482154e-04,  1.99793503e-01,\n",
       "         -4.05398697e-01,  2.66054422e-01, -5.32971285e-02,\n",
       "         -3.41410786e-02,  6.47835284e-02,  4.56927158e-03,\n",
       "         -3.32323872e-02, -3.85525376e-02, -3.35600711e-02,\n",
       "          1.98710531e-01],\n",
       "        [-5.92017829e-01,  5.37130713e-01,  2.12916434e-01,\n",
       "         -9.10088792e-03,  2.68078130e-03, -5.04222989e-01,\n",
       "         -5.06024659e-01, -2.55979866e-01,  4.37151015e-01,\n",
       "         -3.10363546e-02,  4.64191943e-01, -4.12036628e-02,\n",
       "          2.02877875e-02,  1.78771224e-02, -3.78462613e-01,\n",
       "         -8.33558813e-02],\n",
       "        [-4.34430718e-01,  4.28997763e-02,  1.24818027e-01,\n",
       "          2.56095249e-02, -1.84066501e-02, -3.18226516e-01,\n",
       "         -3.20048392e-01, -2.69154817e-01,  2.12099016e-01,\n",
       "         -1.19972555e-02,  8.85733068e-02, -5.90257496e-02,\n",
       "         -3.66348028e-02, -2.12655645e-02, -4.75715131e-01,\n",
       "         -2.62773782e-01],\n",
       "        [-6.19053960e-01,  1.94647506e-01,  1.00059450e-01,\n",
       "         -2.90799811e-02,  2.98467353e-02, -2.08586961e-01,\n",
       "         -4.44461972e-01, -1.71929389e-01,  1.78104669e-01,\n",
       "         -2.74428376e-03,  5.44094220e-02, -8.39878842e-02,\n",
       "         -8.97469092e-03, -5.45184575e-02, -4.04652119e-01,\n",
       "         -1.55868158e-01],\n",
       "        [-2.93052673e-01,  7.85107836e-02, -1.05220258e-01,\n",
       "         -6.17736913e-02,  2.12852154e-02,  6.24363832e-02,\n",
       "         -2.41733015e-01, -5.13705164e-02, -1.00981770e-02,\n",
       "         -7.14684054e-02, -9.57048759e-02, -3.92035209e-02,\n",
       "         -4.75087836e-02,  3.41861956e-02, -3.67962532e-02,\n",
       "         -6.68147728e-02],\n",
       "        [-2.89189499e-02,  2.10998610e-01, -3.55069675e-02,\n",
       "         -3.37994173e-02, -1.35838017e-02,  5.06131388e-02,\n",
       "         -1.27350047e-01,  6.67755827e-02,  2.07991097e-02,\n",
       "         -1.93782952e-02,  6.26385584e-02, -4.24169302e-02,\n",
       "          1.95837077e-02, -3.81381251e-02, -5.79481572e-03,\n",
       "         -1.90959573e-02],\n",
       "        [-2.42667377e-01, -5.64851351e-02,  1.45536466e-02,\n",
       "         -2.21369565e-02,  1.34721361e-02,  2.47661248e-02,\n",
       "         -2.05008388e-01,  3.07969246e-02, -1.29411623e-01,\n",
       "         -1.51833473e-02, -2.37911344e-02,  7.57656852e-03,\n",
       "         -3.74857225e-02, -3.68306413e-03, -3.74502838e-02,\n",
       "         -4.25303914e-03],\n",
       "        [-9.95927453e-02,  1.14708669e-01, -1.00905411e-01,\n",
       "         -3.30403671e-02, -1.02490047e-02, -4.31925282e-02,\n",
       "         -1.43329695e-01, -1.00585476e-01, -4.09315564e-02,\n",
       "         -7.34948218e-02, -1.26933500e-01, -3.66837196e-02,\n",
       "          5.45115722e-03,  1.83740091e-02, -3.22993435e-02,\n",
       "         -1.01919211e-01],\n",
       "        [ 1.91984531e-02, -6.06991686e-02, -1.63446274e-02,\n",
       "         -2.66154204e-02, -2.34598536e-02,  8.27484578e-02,\n",
       "          1.23034418e-01, -1.94926038e-01,  4.05743197e-02,\n",
       "          4.14782166e-02, -1.22535497e-01,  2.87238397e-02,\n",
       "          3.70138772e-02,  2.12153587e-02, -3.09208743e-02,\n",
       "         -9.72462222e-02],\n",
       "        [ 2.20158752e-02,  4.13899049e-02,  1.35010034e-02,\n",
       "         -7.29390560e-03,  1.52567483e-03, -1.43382356e-01,\n",
       "         -5.19993016e-03,  2.87360754e-02, -1.16695510e-02,\n",
       "          3.02375620e-03, -9.22369584e-02, -9.66134071e-02,\n",
       "          2.81003397e-02, -1.24695534e-02, -5.38937926e-01,\n",
       "         -1.17844023e-01],\n",
       "        [-1.52532667e-01, -3.64464186e-02, -1.09001413e-01,\n",
       "         -2.56107878e-02, -3.33346799e-02,  5.27104735e-03,\n",
       "         -2.02563792e-01,  1.18084431e-01, -2.32982591e-01,\n",
       "          1.91749092e-02, -8.08484945e-03, -4.15722318e-02,\n",
       "          3.16288020e-03,  4.61875163e-02, -2.61905342e-01,\n",
       "          1.03364559e-02],\n",
       "        [-1.06729954e-01,  2.51075149e-01,  9.19696018e-02,\n",
       "          2.45748530e-03,  1.79642439e-02, -3.87484819e-01,\n",
       "         -3.68913352e-01, -2.21987162e-02,  1.96463674e-01,\n",
       "         -7.39832520e-02,  1.18690386e-01, -4.73318920e-02,\n",
       "         -3.65278753e-03,  2.67165489e-02, -4.27457362e-01,\n",
       "         -1.71329543e-01]], dtype=float32),\n",
       " array([-0.18170522, -0.48055416, -0.05287031, -0.01354179, -0.0136634 ,\n",
       "         0.28427374,  0.03480063,  0.10514105, -0.35501385, -0.02130608,\n",
       "        -0.3698817 , -0.00713619, -0.0055478 , -0.00814768,  0.05265973,\n",
       "         0.11991537], dtype=float32)]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights0 = neural_network.layers[0].get_weights()\n",
    "weights0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # we can get weights of the other layers too \n",
    "len(weights0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 16)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#weights first position: neuron weights\n",
    "#weights second position: bias weights\n",
    "len(weights0[0]), len(weights0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step \n"
     ]
    }
   ],
   "source": [
    "predict = neural_network.predict(X_test)\n",
    "predict = predict > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [False],\n",
       "       [False],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [ True],\n",
       "       [False],\n",
       "       [ True]])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>143 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "416  1\n",
       "186  0\n",
       "260  0\n",
       "491  1\n",
       "504  1\n",
       "..  ..\n",
       "419  1\n",
       "80   1\n",
       "190  0\n",
       "432  0\n",
       "294  1\n",
       "\n",
       "[143 rows x 1 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# now we should compare to the data of y_test\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8251748251748252"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[32, 23],\n",
       "       [ 2, 86]], dtype=int64)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 15)"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#successes  x errors \n",
    "44+84,1+14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - binary_accuracy: 0.8211 - loss: 2.0079  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.9413838386535645, 0.8251748085021973]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# it returns an array with error and accuracy values\n",
    "neural_network.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
